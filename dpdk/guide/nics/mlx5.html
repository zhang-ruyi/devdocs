

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>34. MLX5 poll mode driver &mdash; Data Plane Development Kit 20.11.0 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="35. MVNETA Poll Mode Driver" href="mvneta.html" />
    <link rel="prev" title="33. MLX4 poll mode driver library" href="mlx4.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Data Plane Development Kit
          

          
            
            <img src="../_static/DPDK_logo_vertical_rev_small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                20.11.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../linux_gsg/index.html">Getting Started Guide for Linux</a></li>
<li class="toctree-l1"><a class="reference internal" href="../freebsd_gsg/index.html">Getting Started Guide for FreeBSD</a></li>
<li class="toctree-l1"><a class="reference internal" href="../windows_gsg/index.html">Getting Started Guide for Windows</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sample_app_ug/index.html">Sample Applications User Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prog_guide/index.html">Programmer’s Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../howto/index.html">HowTo Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tools/index.html">DPDK Tools User Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testpmd_app_ug/index.html">Testpmd Application User Guide</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Network Interface Controller Drivers</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="overview.html">1. Overview of Networking Drivers</a></li>
<li class="toctree-l2"><a class="reference internal" href="features.html">2. Features Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="build_and_test.html">3. Compiling and testing a PMD for a NIC</a></li>
<li class="toctree-l2"><a class="reference internal" href="af_packet.html">4. AF_PACKET Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="af_xdp.html">5. AF_XDP Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="ark.html">6. ARK Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="atlantic.html">7. Aquantia Atlantic DPDK Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="avp.html">8. AVP Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="axgbe.html">9. AXGBE Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="bnx2x.html">10. BNX2X Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="bnxt.html">11. BNXT Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="cxgbe.html">12. CXGBE Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="dpaa.html">13. DPAA Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="dpaa2.html">14. DPAA2 Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="e1000em.html">15. Driver for VM Emulated Devices</a></li>
<li class="toctree-l2"><a class="reference internal" href="ena.html">16. ENA Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="enetc.html">17. ENETC Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="enic.html">18. ENIC Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="fm10k.html">19. FM10K Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="hinic.html">20. HINIC Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="hns3.html">21. HNS3 Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="i40e.html">22. I40E Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="ice.html">23. ICE Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="igb.html">24. IGB Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="igc.html">25. IGC Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="ionic.html">26. IONIC Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="ipn3ke.html">27. IPN3KE Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="ixgbe.html">28. IXGBE Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="intel_vf.html">29. Intel Virtual Function Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="kni.html">30. KNI Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="liquidio.html">31. LiquidIO VF Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="memif.html">32. Memif Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlx4.html">33. MLX4 poll mode driver library</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">34. MLX5 poll mode driver</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#design">34.1. Design</a></li>
<li class="toctree-l3"><a class="reference internal" href="#features">34.2. Features</a></li>
<li class="toctree-l3"><a class="reference internal" href="#limitations">34.3. Limitations</a></li>
<li class="toctree-l3"><a class="reference internal" href="#statistics">34.4. Statistics</a></li>
<li class="toctree-l3"><a class="reference internal" href="#configuration">34.5. Configuration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#compilation-options">34.5.1. Compilation options</a></li>
<li class="toctree-l4"><a class="reference internal" href="#environment-variables">34.5.2. Environment variables</a></li>
<li class="toctree-l4"><a class="reference internal" href="#run-time-configuration">34.5.3. Run-time configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#firmware-configuration">34.5.4. Firmware configuration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#prerequisites">34.6. Prerequisites</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#installation">34.6.1. Installation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#supported-nics">34.7. Supported NICs</a></li>
<li class="toctree-l3"><a class="reference internal" href="#quick-start-guide-on-ofed-en">34.8. Quick Start Guide on OFED/EN</a></li>
<li class="toctree-l3"><a class="reference internal" href="#enable-switchdev-mode">34.9. Enable switchdev mode</a></li>
<li class="toctree-l3"><a class="reference internal" href="#performance-tuning">34.10. Performance tuning</a></li>
<li class="toctree-l3"><a class="reference internal" href="#rx-burst-functions">34.11. Rx burst functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="#supported-hardware-offloads">34.12. Supported hardware offloads</a></li>
<li class="toctree-l3"><a class="reference internal" href="#notes-for-metadata">34.13. Notes for metadata</a></li>
<li class="toctree-l3"><a class="reference internal" href="#notes-for-rte-flow">34.14. Notes for rte_flow</a></li>
<li class="toctree-l3"><a class="reference internal" href="#notes-for-testpmd">34.15. Notes for testpmd</a></li>
<li class="toctree-l3"><a class="reference internal" href="#usage-example">34.16. Usage example</a></li>
<li class="toctree-l3"><a class="reference internal" href="#how-to-dump-flows">34.17. How to dump flows</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="mvneta.html">35. MVNETA Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="mvpp2.html">36. MVPP2 Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="netvsc.html">37. Netvsc poll mode driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="nfb.html">38. NFB poll mode driver library</a></li>
<li class="toctree-l2"><a class="reference internal" href="nfp.html">39. NFP poll mode driver library</a></li>
<li class="toctree-l2"><a class="reference internal" href="null.html">40. NULL Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="octeontx.html">41. OCTEON TX Poll Mode driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="octeontx2.html">42. OCTEON TX2 Poll Mode driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="pfe.html">43. PFE Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="qede.html">44. QEDE Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="sfc_efx.html">45. Solarflare libefx-based Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="softnic.html">46. Soft NIC Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="szedata2.html">47. SZEDATA2 poll mode driver library</a></li>
<li class="toctree-l2"><a class="reference internal" href="tap.html">48. Tun|Tap Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="thunderx.html">49. ThunderX NICVF Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="txgbe.html">50. TXGBE Poll Mode Driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="vdev_netvsc.html">51. VDEV_NETVSC driver</a></li>
<li class="toctree-l2"><a class="reference internal" href="virtio.html">52. Poll Mode Driver for Emulated Virtio NIC</a></li>
<li class="toctree-l2"><a class="reference internal" href="vhost.html">53. Poll Mode Driver that wraps vhost library</a></li>
<li class="toctree-l2"><a class="reference internal" href="vmxnet3.html">54. Poll Mode Driver for Paravirtual VMXNET3 NIC</a></li>
<li class="toctree-l2"><a class="reference internal" href="pcap_ring.html">55. Libpcap and Ring Based Poll Mode Drivers</a></li>
<li class="toctree-l2"><a class="reference internal" href="fail_safe.html">56. Fail-safe poll mode driver library</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../bbdevs/index.html">Baseband Device Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cryptodevs/index.html">Crypto Device Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../compressdevs/index.html">Compression Device Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../vdpadevs/index.html">vDPA Device Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../regexdevs/index.html">REGEX Device Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../eventdevs/index.html">Event Device Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rawdevs/index.html">Rawdev Drivers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mempool/index.html">Mempool Device Driver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../platform/index.html">Platform Specific Guides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributing/index.html">Contributor’s Guidelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rel_notes/index.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq/index.html">FAQ</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Data Plane Development Kit</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">Network Interface Controller Drivers</a> &raquo;</li>
        
      <li><span class="section-number">34. </span>MLX5 poll mode driver</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/nics/mlx5.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="mlx5-poll-mode-driver">
<h1><span class="section-number">34. </span>MLX5 poll mode driver</h1>
<p>The MLX5 poll mode driver library (<strong>librte_net_mlx5</strong>) provides support
for <strong>Mellanox ConnectX-4</strong>, <strong>Mellanox ConnectX-4 Lx</strong> , <strong>Mellanox
ConnectX-5</strong>, <strong>Mellanox ConnectX-6</strong>, <strong>Mellanox ConnectX-6 Dx</strong>, <strong>Mellanox
ConnectX-6 Lx</strong>, <strong>Mellanox BlueField</strong> and <strong>Mellanox BlueField-2</strong> families
of 10/25/40/50/100/200 Gb/s adapters as well as their virtual functions (VF)
in SR-IOV context.</p>
<p>Information and documentation about these adapters can be found on the
<a class="reference external" href="http://www.mellanox.com">Mellanox website</a>. Help is also provided by the
<a class="reference external" href="http://community.mellanox.com/welcome">Mellanox community</a>.</p>
<p>There is also a <a class="reference external" href="http://www.mellanox.com/page/products_dyn?product_family=209&amp;mtag=pmd_for_dpdk">section dedicated to this poll mode driver</a>.</p>
<div class="section" id="design">
<h2><span class="section-number">34.1. </span>Design</h2>
<p>Besides its dependency on libibverbs (that implies libmlx5 and associated
kernel support), librte_net_mlx5 relies heavily on system calls for control
operations such as querying/updating the MTU and flow control parameters.</p>
<p>For security reasons and robustness, this driver only deals with virtual
memory addresses. The way resources allocations are handled by the kernel,
combined with hardware specifications that allow to handle virtual memory
addresses directly, ensure that DPDK applications cannot access random
physical memory (or memory that does not belong to the current process).</p>
<p>This capability allows the PMD to coexist with kernel network interfaces
which remain functional, although they stop receiving unicast packets as
long as they share the same MAC address.
This means legacy linux control tools (for example: ethtool, ifconfig and
more) can operate on the same network interfaces that owned by the DPDK
application.</p>
<p>The PMD can use libibverbs and libmlx5 to access the device firmware
or directly the hardware components.
There are different levels of objects and bypassing abilities
to get the best performances:</p>
<ul class="simple">
<li><p>Verbs is a complete high-level generic API</p></li>
<li><p>Direct Verbs is a device-specific API</p></li>
<li><p>DevX allows to access firmware objects</p></li>
<li><p>Direct Rules manages flow steering at low-level hardware layer</p></li>
</ul>
<p>Enabling librte_net_mlx5 causes DPDK applications to be linked against
libibverbs.</p>
</div>
<div class="section" id="features">
<h2><span class="section-number">34.2. </span>Features</h2>
<ul class="simple">
<li><p>Multi arch support: x86_64, POWER8, ARMv8, i686.</p></li>
<li><p>Multiple TX and RX queues.</p></li>
<li><p>Support for scattered TX frames.</p></li>
<li><p>Advanced support for scattered Rx frames with tunable buffer attributes.</p></li>
<li><p>IPv4, IPv6, TCPv4, TCPv6, UDPv4 and UDPv6 RSS on any number of queues.</p></li>
<li><p>RSS using different combinations of fields: L3 only, L4 only or both,
and source only, destination only or both.</p></li>
<li><p>Several RSS hash keys, one for each flow type.</p></li>
<li><p>Default RSS operation with no hash key specification.</p></li>
<li><p>Configurable RETA table.</p></li>
<li><p>Link flow control (pause frame).</p></li>
<li><p>Support for multiple MAC addresses.</p></li>
<li><p>VLAN filtering.</p></li>
<li><p>RX VLAN stripping.</p></li>
<li><p>TX VLAN insertion.</p></li>
<li><p>RX CRC stripping configuration.</p></li>
<li><p>Promiscuous mode on PF and VF.</p></li>
<li><p>Multicast promiscuous mode on PF and VF.</p></li>
<li><p>Hardware checksum offloads.</p></li>
<li><p>Flow director (RTE_FDIR_MODE_PERFECT, RTE_FDIR_MODE_PERFECT_MAC_VLAN and
RTE_ETH_FDIR_REJECT).</p></li>
<li><p>Flow API, including <a class="reference internal" href="../prog_guide/rte_flow.html#flow-isolated-mode"><span class="std std-ref">Flow isolated mode</span></a>.</p></li>
<li><p>Multiple process.</p></li>
<li><p>KVM and VMware ESX SR-IOV modes are supported.</p></li>
<li><p>RSS hash result is supported.</p></li>
<li><p>Hardware TSO for generic IP or UDP tunnel, including VXLAN and GRE.</p></li>
<li><p>Hardware checksum Tx offload for generic IP or UDP tunnel, including VXLAN and GRE.</p></li>
<li><p>RX interrupts.</p></li>
<li><p>Statistics query including Basic, Extended and per queue.</p></li>
<li><p>Rx HW timestamp.</p></li>
<li><p>Tunnel types: VXLAN, L3 VXLAN, VXLAN-GPE, GRE, MPLSoGRE, MPLSoUDP, IP-in-IP, Geneve, GTP.</p></li>
<li><p>Tunnel HW offloads: packet type, inner/outer RSS, IP and UDP checksum verification.</p></li>
<li><p>NIC HW offloads: encapsulation (vxlan, gre, mplsoudp, mplsogre), NAT, routing, TTL
increment/decrement, count, drop, mark. For details please see <a class="reference internal" href="#mlx5-offloads-support"><span class="std std-ref">Supported hardware offloads</span></a>.</p></li>
<li><p>Flow insertion rate of more then million flows per second, when using Direct Rules.</p></li>
<li><p>Support for multiple rte_flow groups.</p></li>
<li><p>Per packet no-inline hint flag to disable packet data copying into Tx descriptors.</p></li>
<li><p>Hardware LRO.</p></li>
<li><p>Hairpin.</p></li>
<li><p>Multiple-thread flow insertion.</p></li>
</ul>
</div>
<div class="section" id="limitations">
<h2><span class="section-number">34.3. </span>Limitations</h2>
<ul>
<li><p>For secondary process:</p>
<ul class="simple">
<li><p>Forked secondary process not supported.</p></li>
<li><p>External memory unregistered in EAL memseg list cannot be used for DMA
unless such memory has been registered by <code class="docutils literal notranslate"><span class="pre">mlx5_mr_update_ext_mp()</span></code> in
primary process and remapped to the same virtual address in secondary
process. If the external memory is registered by primary process but has
different virtual address in secondary process, unexpected error may happen.</p></li>
</ul>
</li>
<li><p>When using Verbs flow engine (<code class="docutils literal notranslate"><span class="pre">dv_flow_en</span></code> = 0), flow pattern without any
specific VLAN will match for VLAN packets as well:</p>
<p>When VLAN spec is not specified in the pattern, the matching rule will be created with VLAN as a wild card.
Meaning, the flow rule:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>flow create 0 ingress pattern eth / vlan vid is 3 / ipv4 / end ...
</pre></div>
</div>
<p>Will only match vlan packets with vid=3. and the flow rule:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>flow create 0 ingress pattern eth / ipv4 / end ...
</pre></div>
</div>
<p>Will match any ipv4 packet (VLAN included).</p>
</li>
<li><p>When using Verbs flow engine (<code class="docutils literal notranslate"><span class="pre">dv_flow_en</span></code> = 0), multi-tagged(QinQ) match is not supported.</p></li>
<li><p>When using DV flow engine (<code class="docutils literal notranslate"><span class="pre">dv_flow_en</span></code> = 1), flow pattern with any VLAN specification will match only single-tagged packets unless the ETH item <code class="docutils literal notranslate"><span class="pre">type</span></code> field is 0x88A8 or the VLAN item <code class="docutils literal notranslate"><span class="pre">has_more_vlan</span></code> field is 1.
The flow rule:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>flow create 0 ingress pattern eth / ipv4 / end ...
</pre></div>
</div>
<p>Will match any ipv4 packet.
The flow rules:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>flow create 0 ingress pattern eth / vlan / end ...
flow create 0 ingress pattern eth has_vlan is 1 / end ...
flow create 0 ingress pattern eth type is 0x8100 / end ...
</pre></div>
</div>
<p>Will match single-tagged packets only, with any VLAN ID value.
The flow rules:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>flow create 0 ingress pattern eth type is 0x88A8 / end ...
flow create 0 ingress pattern eth / vlan has_more_vlan is 1 / end ...
</pre></div>
</div>
<p>Will match multi-tagged packets only, with any VLAN ID value.</p>
</li>
<li><p>A flow pattern with 2 sequential VLAN items is not supported.</p></li>
<li><p>VLAN pop offload command:</p>
<ul class="simple">
<li><p>Flow rules having a VLAN pop offload command as one of their actions and
are lacking a match on VLAN as one of their items are not supported.</p></li>
<li><p>The command is not supported on egress traffic.</p></li>
</ul>
</li>
<li><p>VLAN push offload is not supported on ingress traffic.</p></li>
<li><p>VLAN set PCP offload is not supported on existing headers.</p></li>
<li><p>A multi segment packet must have not more segments than reported by dev_infos_get()
in tx_desc_lim.nb_seg_max field. This value depends on maximal supported Tx descriptor
size and <code class="docutils literal notranslate"><span class="pre">txq_inline_min</span></code> settings and may be from 2 (worst case forced by maximal
inline settings) to 58.</p></li>
<li><p>Flows with a VXLAN Network Identifier equal (or ends to be equal)
to 0 are not supported.</p></li>
<li><p>L3 VXLAN and VXLAN-GPE tunnels cannot be supported together with MPLSoGRE and MPLSoUDP.</p></li>
<li><p>Match on Geneve header supports the following fields only:</p>
<blockquote>
<div><ul class="simple">
<li><p>VNI</p></li>
<li><p>OAM</p></li>
<li><p>protocol type</p></li>
<li><p>options length
Currently, the only supported options length value is 0.</p></li>
</ul>
</div></blockquote>
</li>
<li><p>VF: flow rules created on VF devices can only match traffic targeted at the
configured MAC addresses (see <code class="docutils literal notranslate"><span class="pre">rte_eth_dev_mac_addr_add()</span></code>).</p></li>
<li><p>Match on GTP tunnel header item supports the following fields only:</p>
<blockquote>
<div><ul class="simple">
<li><p>v_pt_rsv_flags: E flag, S flag, PN flag</p></li>
<li><p>msg_type</p></li>
<li><p>teid</p></li>
</ul>
</div></blockquote>
</li>
<li><p>No Tx metadata go to the E-Switch steering domain for the Flow group 0.
The flows within group 0 and set metadata action are rejected by hardware.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>MAC addresses not already present in the bridge table of the associated
kernel network device will be added and cleaned up by the PMD when closing
the device. In case of ungraceful program termination, some entries may
remain present and should be removed manually by other means.</p>
</div>
<ul>
<li><p>Buffer split offload is supported with regular Rx burst routine only,
no MPRQ feature or vectorized code can be engaged.</p></li>
<li><p>When Multi-Packet Rx queue is configured (<code class="docutils literal notranslate"><span class="pre">mprq_en</span></code>), a Rx packet can be
externally attached to a user-provided mbuf with having EXT_ATTACHED_MBUF in
ol_flags. As the mempool for the external buffer is managed by PMD, all the
Rx mbufs must be freed before the device is closed. Otherwise, the mempool of
the external buffers will be freed by PMD and the application which still
holds the external buffers may be corrupted.</p></li>
<li><p>If Multi-Packet Rx queue is configured (<code class="docutils literal notranslate"><span class="pre">mprq_en</span></code>) and Rx CQE compression is
enabled (<code class="docutils literal notranslate"><span class="pre">rxq_cqe_comp_en</span></code>) at the same time, RSS hash result is not fully
supported. Some Rx packets may not have PKT_RX_RSS_HASH.</p></li>
<li><p>IPv6 Multicast messages are not supported on VM, while promiscuous mode
and allmulticast mode are both set to off.
To receive IPv6 Multicast messages on VM, explicitly set the relevant
MAC address using rte_eth_dev_mac_addr_add() API.</p></li>
<li><p>To support a mixed traffic pattern (some buffers from local host memory, some
buffers from other devices) with high bandwidth, a mbuf flag is used.</p>
<p>An application hints the PMD whether or not it should try to inline the
given mbuf data buffer. PMD should do the best effort to act upon this request.</p>
<p>The hint flag <code class="docutils literal notranslate"><span class="pre">RTE_PMD_MLX5_FINE_GRANULARITY_INLINE</span></code> is dynamic,
registered by application with rte_mbuf_dynflag_register(). This flag is
purely driver-specific and declared in PMD specific header <code class="docutils literal notranslate"><span class="pre">rte_pmd_mlx5.h</span></code>,
which is intended to be used by the application.</p>
<p>To query the supported specific flags in runtime,
the function <code class="docutils literal notranslate"><span class="pre">rte_pmd_mlx5_get_dyn_flag_names</span></code> returns the array of
currently (over present hardware and configuration) supported specific flags.
The “not inline hint” feature operating flow is the following one:</p>
<blockquote>
<div><ul class="simple">
<li><p>application starts</p></li>
<li><p>probe the devices, ports are created</p></li>
<li><p>query the port capabilities</p></li>
<li><p>if port supporting the feature is found</p></li>
<li><p>register dynamic flag <code class="docutils literal notranslate"><span class="pre">RTE_PMD_MLX5_FINE_GRANULARITY_INLINE</span></code></p></li>
<li><p>application starts the ports</p></li>
<li><p>on <code class="docutils literal notranslate"><span class="pre">dev_start()</span></code> PMD checks whether the feature flag is registered and
enables the feature support in datapath</p></li>
<li><p>application might set the registered flag bit in <code class="docutils literal notranslate"><span class="pre">ol_flags</span></code> field
of mbuf being sent and PMD will handle ones appropriately.</p></li>
</ul>
</div></blockquote>
</li>
<li><p>The amount of descriptors in Tx queue may be limited by data inline settings.
Inline data require the more descriptor building blocks and overall block
amount may exceed the hardware supported limits. The application should
reduce the requested Tx size or adjust data inline settings with
<code class="docutils literal notranslate"><span class="pre">txq_inline_max</span></code> and <code class="docutils literal notranslate"><span class="pre">txq_inline_mpw</span></code> devargs keys.</p></li>
<li><p>To provide the packet send scheduling on mbuf timestamps the <code class="docutils literal notranslate"><span class="pre">tx_pp</span></code>
parameter should be specified.
When PMD sees the RTE_MBUF_DYNFLAG_TX_TIMESTAMP_NAME set on the packet
being sent it tries to synchronize the time of packet appearing on
the wire with the specified packet timestamp. It the specified one
is in the past it should be ignored, if one is in the distant future
it should be capped with some reasonable value (in range of seconds).
These specific cases (“too late” and “distant future”) can be optionally
reported via device xstats to assist applications to detect the
time-related problems.</p>
<p>The timestamp upper “too-distant-future” limit
at the moment of invoking the Tx burst routine
can be estimated as <code class="docutils literal notranslate"><span class="pre">tx_pp</span></code> option (in nanoseconds) multiplied by 2^23.
Please note, for the testpmd txonly mode,
the limit is deduced from the expression:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>(n_tx_descriptors / burst_size + 1) * inter_burst_gap
</pre></div>
</div>
<p>There is no any packet reordering according timestamps is supposed,
neither within packet burst, nor between packets, it is an entirely
application responsibility to generate packets and its timestamps
in desired order. The timestamps can be put only in the first packet
in the burst providing the entire burst scheduling.</p>
</li>
<li><p>E-Switch decapsulation Flow:</p>
<ul class="simple">
<li><p>can be applied to PF port only.</p></li>
<li><p>must specify VF port action (packet redirection from PF to VF).</p></li>
<li><p>optionally may specify tunnel inner source and destination MAC addresses.</p></li>
</ul>
</li>
<li><p>E-Switch  encapsulation Flow:</p>
<ul class="simple">
<li><p>can be applied to VF ports only.</p></li>
<li><p>must specify PF port action (packet redirection from VF to PF).</p></li>
</ul>
</li>
<li><p>Raw encapsulation:</p>
<ul class="simple">
<li><p>The input buffer, used as outer header, is not validated.</p></li>
</ul>
</li>
<li><p>Raw decapsulation:</p>
<ul class="simple">
<li><p>The decapsulation is always done up to the outermost tunnel detected by the HW.</p></li>
<li><p>The input buffer, providing the removal size, is not validated.</p></li>
<li><p>The buffer size must match the length of the headers to be removed.</p></li>
</ul>
</li>
<li><p>ICMP(code/type/identifier/sequence number) / ICMP6(code/type) matching, IP-in-IP and MPLS flow matching are all
mutually exclusive features which cannot be supported together
(see <a class="reference internal" href="#mlx5-firmware-config"><span class="std std-ref">Firmware configuration</span></a>).</p></li>
<li><p>LRO:</p>
<ul>
<li><p>Requires DevX and DV flow to be enabled.</p></li>
<li><p>KEEP_CRC offload cannot be supported with LRO.</p></li>
<li><p>The first mbuf length, without head-room,  must be big enough to include the
TCP header (122B).</p></li>
<li><p>Rx queue with LRO offload enabled, receiving a non-LRO packet, can forward
it with size limited to max LRO size, not to max RX packet length.</p></li>
<li><dl class="simple">
<dt>LRO can be used with outer header of TCP packets of the standard format:</dt><dd><p>eth (with or without vlan) / ipv4 or ipv6 / tcp / payload</p>
</dd>
</dl>
<p>Other TCP packets (e.g. with MPLS label) received on Rx queue with LRO enabled, will be received with bad checksum.</p>
</li>
<li><p>LRO packet aggregation is performed by HW only for packet size larger than
<code class="docutils literal notranslate"><span class="pre">lro_min_mss_size</span></code>. This value is reported on device start, when debug
mode is enabled.</p></li>
</ul>
</li>
<li><p>CRC:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">DEV_RX_OFFLOAD_KEEP_CRC</span></code> cannot be supported with decapsulation
for some NICs (such as ConnectX-6 Dx, ConnectX-6 Lx, and BlueField-2).
The capability bit <code class="docutils literal notranslate"><span class="pre">scatter_fcs_w_decap_disable</span></code> shows NIC support.</p></li>
</ul>
</li>
<li><p>Sample flow:</p>
<ul class="simple">
<li><p>Supports <code class="docutils literal notranslate"><span class="pre">RTE_FLOW_ACTION_TYPE_SAMPLE</span></code> action only within NIC Rx and E-Switch steering domain.</p></li>
<li><p>The E-Switch Sample flow must have the eswitch_manager VPORT destination (PF or ECPF) and no additional actions.</p></li>
<li><p>For ConnectX-5, the <code class="docutils literal notranslate"><span class="pre">RTE_FLOW_ACTION_TYPE_SAMPLE</span></code> is typically used as first action in the E-Switch egress flow if with header modify or encapsulation actions.</p></li>
</ul>
</li>
<li><p>IPv6 header item ‘proto’ field, indicating the next header protocol, should
not be set as extension header.
In case the next header is an extension header, it should not be specified in
IPv6 header item ‘proto’ field.
The last extension header item ‘next header’ field can specify the following
header protocol type.</p></li>
<li><p>Hairpin:</p>
<ul class="simple">
<li><p>Hairpin between two ports could only manual binding and explicit Tx flow mode. For single port hairpin, all the combinations of auto/manual binding and explicit/implicit Tx flow mode could be supported.</p></li>
<li><p>Hairpin in switchdev SR-IOV mode is not supported till now.</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="statistics">
<h2><span class="section-number">34.4. </span>Statistics</h2>
<p>MLX5 supports various methods to report statistics:</p>
<p>Port statistics can be queried using <code class="docutils literal notranslate"><span class="pre">rte_eth_stats_get()</span></code>. The received and sent statistics are through SW only and counts the number of packets received or sent successfully by the PMD. The imissed counter is the amount of packets that could not be delivered to SW because a queue was full. Packets not received due to congestion in the bus or on the NIC can be queried via the rx_discards_phy xstats counter.</p>
<p>Extended statistics can be queried using <code class="docutils literal notranslate"><span class="pre">rte_eth_xstats_get()</span></code>. The extended statistics expose a wider set of counters counted by the device. The extended port statistics counts the number of packets received or sent successfully by the port. As Mellanox NICs are using the <a class="reference internal" href="../linux_gsg/linux_drivers.html#linux-gsg-linux-drivers"><span class="std std-ref">Bifurcated Linux Driver</span></a> those counters counts also packet received or sent by the Linux kernel. The counters with <code class="docutils literal notranslate"><span class="pre">_phy</span></code> suffix counts the total events on the physical port, therefore not valid for VF.</p>
<p>Finally per-flow statistics can by queried using <code class="docutils literal notranslate"><span class="pre">rte_flow_query</span></code> when attaching a count action for specific flow. The flow counter counts the number of packets received successfully by the port and match the specific flow.</p>
</div>
<div class="section" id="configuration">
<h2><span class="section-number">34.5. </span>Configuration</h2>
<div class="section" id="compilation-options">
<h3><span class="section-number">34.5.1. </span>Compilation options</h3>
<p>The ibverbs libraries can be linked with this PMD in a number of ways,
configured by the <code class="docutils literal notranslate"><span class="pre">ibverbs_link</span></code> build option:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">shared</span></code> (default): the PMD depends on some .so files.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dlopen</span></code>: Split the dependencies glue in a separate library
loaded when needed by dlopen.
It make dependencies on libibverbs and libmlx4 optional,
and has no performance impact.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">static</span></code>: Embed static flavor of the dependencies libibverbs and libmlx4
in the PMD shared library or the executable static binary.</p></li>
</ul>
</div>
<div class="section" id="environment-variables">
<h3><span class="section-number">34.5.2. </span>Environment variables</h3>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">MLX5_GLUE_PATH</span></code></p>
<p>A list of directories in which to search for the rdma-core “glue” plug-in,
separated by colons or semi-colons.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">MLX5_SHUT_UP_BF</span></code></p>
<p>Configures HW Tx doorbell register as IO-mapped.</p>
<p>By default, the HW Tx doorbell is configured as a write-combining register.
The register would be flushed to HW usually when the write-combining buffer
becomes full, but it depends on CPU design.</p>
<p>Except for vectorized Tx burst routines, a write memory barrier is enforced
after updating the register so that the update can be immediately visible to
HW.</p>
<p>When vectorized Tx burst is called, the barrier is set only if the burst size
is not aligned to MLX5_VPMD_TX_MAX_BURST. However, setting this environmental
variable will bring better latency even though the maximum throughput can
slightly decline.</p>
</li>
</ul>
</div>
<div class="section" id="run-time-configuration">
<h3><span class="section-number">34.5.3. </span>Run-time configuration</h3>
<ul class="simple">
<li><p>librte_net_mlx5 brings kernel network interfaces up during initialization
because it is affected by their state. Forcing them down prevents packets
reception.</p></li>
<li><p><strong>ethtool</strong> operations on related kernel interfaces also affect the PMD.</p></li>
</ul>
<div class="section" id="run-as-non-root">
<h4><span class="section-number">34.5.3.1. </span>Run as non-root</h4>
<p>In order to run as a non-root user,
some capabilities must be granted to the application:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>setcap cap_sys_admin,cap_net_admin,cap_net_raw,cap_ipc_lock+ep &lt;dpdk-app&gt;
</pre></div>
</div>
<p>Below are the reasons of the need for each capability:</p>
<dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">cap_sys_admin</span></code></dt><dd><p>When using physical addresses (PA mode), with Linux &gt;= 4.0,
for access to <code class="docutils literal notranslate"><span class="pre">/proc/self/pagemap</span></code>.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">cap_net_admin</span></code></dt><dd><p>For device configuration.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">cap_net_raw</span></code></dt><dd><p>For raw ethernet queue allocation through kernel driver.</p>
</dd>
<dt><code class="docutils literal notranslate"><span class="pre">cap_ipc_lock</span></code></dt><dd><p>For DMA memory pinning.</p>
</dd>
</dl>
</div>
<div class="section" id="driver-options">
<h4><span class="section-number">34.5.3.2. </span>Driver options</h4>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">rxq_cqe_comp_en</span></code> parameter [int]</p>
<p>A nonzero value enables the compression of CQE on RX side. This feature
allows to save PCI bandwidth and improve performance. Enabled by default.
Different compression formats are supported in order to achieve the best
performance for different traffic patterns. Hash RSS format is the default.</p>
<p>Specifying 2 as a <code class="docutils literal notranslate"><span class="pre">rxq_cqe_comp_en</span></code> value selects Flow Tag format for
better compression rate in case of RTE Flow Mark traffic.
Specifying 3 as a <code class="docutils literal notranslate"><span class="pre">rxq_cqe_comp_en</span></code> value selects Checksum format.
Specifying 4 as a <code class="docutils literal notranslate"><span class="pre">rxq_cqe_comp_en</span></code> value selects L3/L4 Header format for
better compression rate in case of mixed TCP/UDP and IPv4/IPv6 traffic.</p>
<p>Supported on:</p>
<ul class="simple">
<li><p>x86_64 with ConnectX-4, ConnectX-4 Lx, ConnectX-5, ConnectX-6, ConnectX-6 Dx,
ConnectX-6 Lx, BlueField and BlueField-2.</p></li>
<li><p>POWER9 and ARMv8 with ConnectX-4 Lx, ConnectX-5, ConnectX-6, ConnectX-6 Dx,
ConnectX-6 Lx, BlueField and BlueField-2.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">rxq_cqe_pad_en</span></code> parameter [int]</p>
<p>A nonzero value enables 128B padding of CQE on RX side. The size of CQE
is aligned with the size of a cacheline of the core. If cacheline size is
128B, the CQE size is configured to be 128B even though the device writes
only 64B data on the cacheline. This is to avoid unnecessary cache
invalidation by device’s two consecutive writes on to one cacheline.
However in some architecture, it is more beneficial to update entire
cacheline with padding the rest 64B rather than striding because
read-modify-write could drop performance a lot. On the other hand,
writing extra data will consume more PCIe bandwidth and could also drop
the maximum throughput. It is recommended to empirically set this
parameter. Disabled by default.</p>
<p>Supported on:</p>
<ul class="simple">
<li><p>CPU having 128B cacheline with ConnectX-5 and BlueField.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">rxq_pkt_pad_en</span></code> parameter [int]</p>
<p>A nonzero value enables padding Rx packet to the size of cacheline on PCI
transaction. This feature would waste PCI bandwidth but could improve
performance by avoiding partial cacheline write which may cause costly
read-modify-copy in memory transaction on some architectures. Disabled by
default.</p>
<p>Supported on:</p>
<ul class="simple">
<li><p>x86_64 with ConnectX-4, ConnectX-4 Lx, ConnectX-5, ConnectX-6, ConnectX-6 Dx,
ConnectX-6 Lx, BlueField and BlueField-2.</p></li>
<li><p>POWER8 and ARMv8 with ConnectX-4 Lx, ConnectX-5, ConnectX-6, ConnectX-6 Dx,
ConnectX-6 Lx, BlueField and BlueField-2.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">mprq_en</span></code> parameter [int]</p>
<p>A nonzero value enables configuring Multi-Packet Rx queues. Rx queue is
configured as Multi-Packet RQ if the total number of Rx queues is
<code class="docutils literal notranslate"><span class="pre">rxqs_min_mprq</span></code> or more. Disabled by default.</p>
<p>Multi-Packet Rx Queue (MPRQ a.k.a Striding RQ) can further save PCIe bandwidth
by posting a single large buffer for multiple packets. Instead of posting a
buffers per a packet, one large buffer is posted in order to receive multiple
packets on the buffer. A MPRQ buffer consists of multiple fixed-size strides
and each stride receives one packet. MPRQ can improve throughput for
small-packet traffic.</p>
<p>When MPRQ is enabled, max_rx_pkt_len can be larger than the size of
user-provided mbuf even if DEV_RX_OFFLOAD_SCATTER isn’t enabled. PMD will
configure large stride size enough to accommodate max_rx_pkt_len as long as
device allows. Note that this can waste system memory compared to enabling Rx
scatter and multi-segment packet.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">mprq_log_stride_num</span></code> parameter [int]</p>
<p>Log 2 of the number of strides for Multi-Packet Rx queue. Configuring more
strides can reduce PCIe traffic further. If configured value is not in the
range of device capability, the default value will be set with a warning
message. The default value is 4 which is 16 strides per a buffer, valid only
if <code class="docutils literal notranslate"><span class="pre">mprq_en</span></code> is set.</p>
<p>The size of Rx queue should be bigger than the number of strides.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">mprq_log_stride_size</span></code> parameter [int]</p>
<p>Log 2 of the size of a stride for Multi-Packet Rx queue. Configuring a smaller
stride size can save some memory and reduce probability of a depletion of all
available strides due to unreleased packets by an application. If configured
value is not in the range of device capability, the default value will be set
with a warning message. The default value is 11 which is 2048 bytes per a
stride, valid only if <code class="docutils literal notranslate"><span class="pre">mprq_en</span></code> is set. With <code class="docutils literal notranslate"><span class="pre">mprq_log_stride_size</span></code> set
it is possible for a packet to span across multiple strides. This mode allows
support of jumbo frames (9K) with MPRQ. The memcopy of some packets (or part
of a packet if Rx scatter is configured) may be required in case there is no
space left for a head room at the end of a stride which incurs some
performance penalty.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">mprq_max_memcpy_len</span></code> parameter [int]</p>
<p>The maximum length of packet to memcpy in case of Multi-Packet Rx queue. Rx
packet is mem-copied to a user-provided mbuf if the size of Rx packet is less
than or equal to this parameter. Otherwise, PMD will attach the Rx packet to
the mbuf by external buffer attachment - <code class="docutils literal notranslate"><span class="pre">rte_pktmbuf_attach_extbuf()</span></code>.
A mempool for external buffers will be allocated and managed by PMD. If Rx
packet is externally attached, ol_flags field of the mbuf will have
EXT_ATTACHED_MBUF and this flag must be preserved. <code class="docutils literal notranslate"><span class="pre">RTE_MBUF_HAS_EXTBUF()</span></code>
checks the flag. The default value is 128, valid only if <code class="docutils literal notranslate"><span class="pre">mprq_en</span></code> is set.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">rxqs_min_mprq</span></code> parameter [int]</p>
<p>Configure Rx queues as Multi-Packet RQ if the total number of Rx queues is
greater or equal to this value. The default value is 12, valid only if
<code class="docutils literal notranslate"><span class="pre">mprq_en</span></code> is set.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">txq_inline</span></code> parameter [int]</p>
<p>Amount of data to be inlined during TX operations. This parameter is
deprecated and converted to the new parameter <code class="docutils literal notranslate"><span class="pre">txq_inline_max</span></code> providing
partial compatibility.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">txqs_min_inline</span></code> parameter [int]</p>
<p>Enable inline data send only when the number of TX queues is greater or equal
to this value.</p>
<p>This option should be used in combination with <code class="docutils literal notranslate"><span class="pre">txq_inline_max</span></code> and
<code class="docutils literal notranslate"><span class="pre">txq_inline_mpw</span></code> below and does not affect <code class="docutils literal notranslate"><span class="pre">txq_inline_min</span></code> settings above.</p>
<p>If this option is not specified the default value 16 is used for BlueField
and 8 for other platforms</p>
<p>The data inlining consumes the CPU cycles, so this option is intended to
auto enable inline data if we have enough Tx queues, which means we have
enough CPU cores and PCI bandwidth is getting more critical and CPU
is not supposed to be bottleneck anymore.</p>
<p>The copying data into WQE improves latency and can improve PPS performance
when PCI back pressure is detected and may be useful for scenarios involving
heavy traffic on many queues.</p>
<p>Because additional software logic is necessary to handle this mode, this
option should be used with care, as it may lower performance when back
pressure is not expected.</p>
<p>If inline data are enabled it may affect the maximal size of Tx queue in
descriptors because the inline data increase the descriptor size and
queue size limits supported by hardware may be exceeded.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">txq_inline_min</span></code> parameter [int]</p>
<p>Minimal amount of data to be inlined into WQE during Tx operations. NICs
may require this minimal data amount to operate correctly. The exact value
may depend on NIC operation mode, requested offloads, etc. It is strongly
recommended to omit this parameter and use the default values. Anyway,
applications using this parameter should take into consideration that
specifying an inconsistent value may prevent the NIC from sending packets.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">txq_inline_min</span></code> key is present the specified value (may be aligned
by the driver in order not to exceed the limits and provide better descriptor
space utilization) will be used by the driver and it is guaranteed that
requested amount of data bytes are inlined into the WQE beside other inline
settings. This key also may update <code class="docutils literal notranslate"><span class="pre">txq_inline_max</span></code> value (default
or specified explicitly in devargs) to reserve the space for inline data.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">txq_inline_min</span></code> key is not present, the value may be queried by the
driver from the NIC via DevX if this feature is available. If there is no DevX
enabled/supported the value 18 (supposing L2 header including VLAN) is set
for ConnectX-4 and ConnectX-4 Lx, and 0 is set by default for ConnectX-5
and newer NICs. If packet is shorter the <code class="docutils literal notranslate"><span class="pre">txq_inline_min</span></code> value, the entire
packet is inlined.</p>
<p>For ConnectX-4 NIC, driver does not allow specifying value below 18
(minimal L2 header, including VLAN), error will be raised.</p>
<p>For ConnectX-4 Lx NIC, it is allowed to specify values below 18, but
it is not recommended and may prevent NIC from sending packets over
some configurations.</p>
<p>Please, note, this minimal data inlining disengages eMPW feature (Enhanced
Multi-Packet Write), because last one does not support partial packet inlining.
This is not very critical due to minimal data inlining is mostly required
by ConnectX-4 and ConnectX-4 Lx, these NICs do not support eMPW feature.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">txq_inline_max</span></code> parameter [int]</p>
<p>Specifies the maximal packet length to be completely inlined into WQE
Ethernet Segment for ordinary SEND method. If packet is larger than specified
value, the packet data won’t be copied by the driver at all, data buffer
is addressed with a pointer. If packet length is less or equal all packet
data will be copied into WQE. This may improve PCI bandwidth utilization for
short packets significantly but requires the extra CPU cycles.</p>
<p>The data inline feature is controlled by number of Tx queues, if number of Tx
queues is larger than <code class="docutils literal notranslate"><span class="pre">txqs_min_inline</span></code> key parameter, the inline feature
is engaged, if there are not enough Tx queues (which means not enough CPU cores
and CPU resources are scarce), data inline is not performed by the driver.
Assigning <code class="docutils literal notranslate"><span class="pre">txqs_min_inline</span></code> with zero always enables the data inline.</p>
<p>The default <code class="docutils literal notranslate"><span class="pre">txq_inline_max</span></code> value is 290. The specified value may be adjusted
by the driver in order not to exceed the limit (930 bytes) and to provide better
WQE space filling without gaps, the adjustment is reflected in the debug log.
Also, the default value (290) may be decreased in run-time if the large transmit
queue size is requested and hardware does not support enough descriptor
amount, in this case warning is emitted. If <code class="docutils literal notranslate"><span class="pre">txq_inline_max</span></code> key is
specified and requested inline settings can not be satisfied then error
will be raised.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">txq_inline_mpw</span></code> parameter [int]</p>
<p>Specifies the maximal packet length to be completely inlined into WQE for
Enhanced MPW method. If packet is large the specified value, the packet data
won’t be copied, and data buffer is addressed with pointer. If packet length
is less or equal, all packet data will be copied into WQE. This may improve PCI
bandwidth utilization for short packets significantly but requires the extra
CPU cycles.</p>
<p>The data inline feature is controlled by number of TX queues, if number of Tx
queues is larger than <code class="docutils literal notranslate"><span class="pre">txqs_min_inline</span></code> key parameter, the inline feature
is engaged, if there are not enough Tx queues (which means not enough CPU cores
and CPU resources are scarce), data inline is not performed by the driver.
Assigning <code class="docutils literal notranslate"><span class="pre">txqs_min_inline</span></code> with zero always enables the data inline.</p>
<p>The default <code class="docutils literal notranslate"><span class="pre">txq_inline_mpw</span></code> value is 268. The specified value may be adjusted
by the driver in order not to exceed the limit (930 bytes) and to provide better
WQE space filling without gaps, the adjustment is reflected in the debug log.
Due to multiple packets may be included to the same WQE with Enhanced Multi
Packet Write Method and overall WQE size is limited it is not recommended to
specify large values for the <code class="docutils literal notranslate"><span class="pre">txq_inline_mpw</span></code>. Also, the default value (268)
may be decreased in run-time if the large transmit queue size is requested
and hardware does not support enough descriptor amount, in this case warning
is emitted. If <code class="docutils literal notranslate"><span class="pre">txq_inline_mpw</span></code> key is  specified and requested inline
settings can not be satisfied then error will be raised.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">txqs_max_vec</span></code> parameter [int]</p>
<p>Enable vectorized Tx only when the number of TX queues is less than or
equal to this value. This parameter is deprecated and ignored, kept
for compatibility issue to not prevent driver from probing.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">txq_mpw_hdr_dseg_en</span></code> parameter [int]</p>
<p>A nonzero value enables including two pointers in the first block of TX
descriptor. The parameter is deprecated and ignored, kept for compatibility
issue.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">txq_max_inline_len</span></code> parameter [int]</p>
<p>Maximum size of packet to be inlined. This limits the size of packet to
be inlined. If the size of a packet is larger than configured value, the
packet isn’t inlined even though there’s enough space remained in the
descriptor. Instead, the packet is included with pointer. This parameter
is deprecated and converted directly to <code class="docutils literal notranslate"><span class="pre">txq_inline_mpw</span></code> providing full
compatibility. Valid only if eMPW feature is engaged.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">txq_mpw_en</span></code> parameter [int]</p>
<p>A nonzero value enables Enhanced Multi-Packet Write (eMPW) for ConnectX-5,
ConnectX-6, ConnectX-6 Dx, ConnectX-6 Lx, BlueField, BlueField-2.
eMPW allows the Tx burst function to pack up multiple packets
in a single descriptor session in order to save PCI bandwidth
and improve performance at the cost of a slightly higher CPU usage.
When <code class="docutils literal notranslate"><span class="pre">txq_inline_mpw</span></code> is set along with <code class="docutils literal notranslate"><span class="pre">txq_mpw_en</span></code>,
Tx burst function copies entire packet data on to Tx descriptor
instead of including pointer of packet.</p>
<p>The Enhanced Multi-Packet Write feature is enabled by default if NIC supports
it, can be disabled by explicit specifying 0 value for <code class="docutils literal notranslate"><span class="pre">txq_mpw_en</span></code> option.
Also, if minimal data inlining is requested by non-zero <code class="docutils literal notranslate"><span class="pre">txq_inline_min</span></code>
option or reported by the NIC, the eMPW feature is disengaged.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">tx_db_nc</span></code> parameter [int]</p>
<p>The rdma core library can map doorbell register in two ways, depending on the
environment variable “MLX5_SHUT_UP_BF”:</p>
<ul class="simple">
<li><p>As regular cached memory (usually with write combining attribute), if the
variable is either missing or set to zero.</p></li>
<li><p>As non-cached memory, if the variable is present and set to not “0” value.</p></li>
</ul>
<p>The type of mapping may slightly affect the Tx performance, the optimal choice
is strongly relied on the host architecture and should be deduced practically.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">tx_db_nc</span></code> is set to zero, the doorbell is forced to be mapped to regular
memory (with write combining), the PMD will perform the extra write memory barrier
after writing to doorbell, it might increase the needed CPU clocks per packet
to send, but latency might be improved.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">tx_db_nc</span></code> is set to one, the doorbell is forced to be mapped to non
cached memory, the PMD will not perform the extra write memory barrier
after writing to doorbell, on some architectures it might improve the
performance.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">tx_db_nc</span></code> is set to two, the doorbell is forced to be mapped to regular
memory, the PMD will use heuristics to decide whether write memory barrier
should be performed. For bursts with size multiple of recommended one (64 pkts)
it is supposed the next burst is coming and no need to issue the extra memory
barrier (it is supposed to be issued in the next coming burst, at least after
descriptor writing). It might increase latency (on some hosts till next
packets transmit) and should be used with care.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">tx_db_nc</span></code> is omitted or set to zero, the preset (if any) environment
variable “MLX5_SHUT_UP_BF” value is used. If there is no “MLX5_SHUT_UP_BF”,
the default <code class="docutils literal notranslate"><span class="pre">tx_db_nc</span></code> value is zero for ARM64 hosts and one for others.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">tx_pp</span></code> parameter [int]</p>
<p>If a nonzero value is specified the driver creates all necessary internal
objects to provide accurate packet send scheduling on mbuf timestamps.
The positive value specifies the scheduling granularity in nanoseconds,
the packet send will be accurate up to specified digits. The allowed range is
from 500 to 1 million of nanoseconds. The negative value specifies the module
of granularity and engages the special test mode the check the schedule rate.
By default (if the <code class="docutils literal notranslate"><span class="pre">tx_pp</span></code> is not specified) send scheduling on timestamps
feature is disabled.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">tx_skew</span></code> parameter [int]</p>
<p>The parameter adjusts the send packet scheduling on timestamps and represents
the average delay between beginning of the transmitting descriptor processing
by the hardware and appearance of actual packet data on the wire. The value
should be provided in nanoseconds and is valid only if <code class="docutils literal notranslate"><span class="pre">tx_pp</span></code> parameter is
specified. The default value is zero.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">tx_vec_en</span></code> parameter [int]</p>
<p>A nonzero value enables Tx vector on ConnectX-5, ConnectX-6, ConnectX-6 Dx,
ConnectX-6 Lx, BlueField and BlueField-2 NICs
if the number of global Tx queues on the port is less than <code class="docutils literal notranslate"><span class="pre">txqs_max_vec</span></code>.
The parameter is deprecated and ignored.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">rx_vec_en</span></code> parameter [int]</p>
<p>A nonzero value enables Rx vector if the port is not configured in
multi-segment otherwise this parameter is ignored.</p>
<p>Enabled by default.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">vf_nl_en</span></code> parameter [int]</p>
<p>A nonzero value enables Netlink requests from the VF to add/remove MAC
addresses or/and enable/disable promiscuous/all multicast on the Netdevice.
Otherwise the relevant configuration must be run with Linux iproute2 tools.
This is a prerequisite to receive this kind of traffic.</p>
<p>Enabled by default, valid only on VF devices ignored otherwise.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">l3_vxlan_en</span></code> parameter [int]</p>
<p>A nonzero value allows L3 VXLAN and VXLAN-GPE flow creation. To enable
L3 VXLAN or VXLAN-GPE, users has to configure firmware and enable this
parameter. This is a prerequisite to receive this kind of traffic.</p>
<p>Disabled by default.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">dv_xmeta_en</span></code> parameter [int]</p>
<p>A nonzero value enables extensive flow metadata support if device is
capable and driver supports it. This can enable extensive support of
<code class="docutils literal notranslate"><span class="pre">MARK</span></code> and <code class="docutils literal notranslate"><span class="pre">META</span></code> item of <code class="docutils literal notranslate"><span class="pre">rte_flow</span></code>. The newly introduced
<code class="docutils literal notranslate"><span class="pre">SET_TAG</span></code> and <code class="docutils literal notranslate"><span class="pre">SET_META</span></code> actions do not depend on <code class="docutils literal notranslate"><span class="pre">dv_xmeta_en</span></code>.</p>
<p>There are some possible configurations, depending on parameter value:</p>
<ul class="simple">
<li><p>0, this is default value, defines the legacy mode, the <code class="docutils literal notranslate"><span class="pre">MARK</span></code> and
<code class="docutils literal notranslate"><span class="pre">META</span></code> related actions and items operate only within NIC Tx and
NIC Rx steering domains, no <code class="docutils literal notranslate"><span class="pre">MARK</span></code> and <code class="docutils literal notranslate"><span class="pre">META</span></code> information crosses
the domain boundaries. The <code class="docutils literal notranslate"><span class="pre">MARK</span></code> item is 24 bits wide, the <code class="docutils literal notranslate"><span class="pre">META</span></code>
item is 32 bits wide and match supported on egress only.</p></li>
<li><p>1, this engages extensive metadata mode, the <code class="docutils literal notranslate"><span class="pre">MARK</span></code> and <code class="docutils literal notranslate"><span class="pre">META</span></code>
related actions and items operate within all supported steering domains,
including FDB, <code class="docutils literal notranslate"><span class="pre">MARK</span></code> and <code class="docutils literal notranslate"><span class="pre">META</span></code> information may cross the domain
boundaries. The <code class="docutils literal notranslate"><span class="pre">MARK</span></code> item is 24 bits wide, the <code class="docutils literal notranslate"><span class="pre">META</span></code> item width
depends on kernel and firmware configurations and might be 0, 16 or
32 bits. Within NIC Tx domain <code class="docutils literal notranslate"><span class="pre">META</span></code> data width is 32 bits for
compatibility, the actual width of data transferred to the FDB domain
depends on kernel configuration and may be vary. The actual supported
width can be retrieved in runtime by series of rte_flow_validate()
trials.</p></li>
<li><p>2, this engages extensive metadata mode, the <code class="docutils literal notranslate"><span class="pre">MARK</span></code> and <code class="docutils literal notranslate"><span class="pre">META</span></code>
related actions and items operate within all supported steering domains,
including FDB, <code class="docutils literal notranslate"><span class="pre">MARK</span></code> and <code class="docutils literal notranslate"><span class="pre">META</span></code> information may cross the domain
boundaries. The <code class="docutils literal notranslate"><span class="pre">META</span></code> item is 32 bits wide, the <code class="docutils literal notranslate"><span class="pre">MARK</span></code> item width
depends on kernel and firmware configurations and might be 0, 16 or
24 bits. The actual supported width can be retrieved in runtime by
series of rte_flow_validate() trials.</p></li>
<li><p>3, this engages tunnel offload mode. In E-Switch configuration, that
mode implicitly activates <code class="docutils literal notranslate"><span class="pre">dv_xmeta_en=1</span></code>.</p></li>
</ul>
<table class="docutils align-default">
<colgroup>
<col style="width: 11%" />
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 24%" />
<col style="width: 24%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Mode</p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">MARK</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">META</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">META</span></code> Tx</p></th>
<th class="head"><p>FDB/Through</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>24 bits</p></td>
<td><p>32 bits</p></td>
<td><p>32 bits</p></td>
<td><p>no</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>24 bits</p></td>
<td><p>vary 0-32</p></td>
<td><p>32 bits</p></td>
<td><p>yes</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>vary 0-32</p></td>
<td><p>32 bits</p></td>
<td><p>32 bits</p></td>
<td><p>yes</p></td>
</tr>
</tbody>
</table>
<p>If there is no E-Switch configuration the <code class="docutils literal notranslate"><span class="pre">dv_xmeta_en</span></code> parameter is
ignored and the device is configured to operate in legacy mode (0).</p>
<p>Disabled by default (set to 0).</p>
<p>The Direct Verbs/Rules (engaged with <code class="docutils literal notranslate"><span class="pre">dv_flow_en</span></code> = 1) supports all
of the extensive metadata features. The legacy Verbs supports FLAG and
MARK metadata actions over NIC Rx steering domain only.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">dv_flow_en</span></code> parameter [int]</p>
<p>A nonzero value enables the DV flow steering assuming it is supported
by the driver (RDMA Core library version is rdma-core-24.0 or higher).</p>
<p>Enabled by default if supported.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">dv_esw_en</span></code> parameter [int]</p>
<p>A nonzero value enables E-Switch using Direct Rules.</p>
<p>Enabled by default if supported.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">lacp_by_user</span></code> parameter [int]</p>
<p>A nonzero value enables the control of LACP traffic by the user application.
When a bond exists in the driver, by default it should be managed by the
kernel and therefore LACP traffic should be steered to the kernel.
If this devarg is set to 1 it will allow the user to manage the bond by
itself and not steer LACP traffic to the kernel.</p>
<p>Disabled by default (set to 0).</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">mr_ext_memseg_en</span></code> parameter [int]</p>
<p>A nonzero value enables extending memseg when registering DMA memory. If
enabled, the number of entries in MR (Memory Region) lookup table on datapath
is minimized and it benefits performance. On the other hand, it worsens memory
utilization because registered memory is pinned by kernel driver. Even if a
page in the extended chunk is freed, that doesn’t become reusable until the
entire memory is freed.</p>
<p>Enabled by default.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">representor</span></code> parameter [list]</p>
<p>This parameter can be used to instantiate DPDK Ethernet devices from
existing port (or VF) representors configured on the device.</p>
<p>It is a standard parameter whose format is described in
<a class="reference internal" href="../prog_guide/poll_mode_drv.html#ethernet-device-standard-device-arguments"><span class="std std-ref">Ethernet Device Standard Device Arguments</span></a>.</p>
<p>For instance, to probe port representors 0 through 2:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>representor=[0-2]
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_dump_files_num</span></code> parameter [int]</p>
<p>The maximum number of files per PMD entity that may be created for debug information.
The files will be created in /var/log directory or in current directory.</p>
<p>set to 128 by default.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">lro_timeout_usec</span></code> parameter [int]</p>
<p>The maximum allowed duration of an LRO session, in micro-seconds.
PMD will set the nearest value supported by HW, which is not bigger than
the input <code class="docutils literal notranslate"><span class="pre">lro_timeout_usec</span></code> value.
If this parameter is not specified, by default PMD will set
the smallest value supported by HW.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">hp_buf_log_sz</span></code> parameter [int]</p>
<p>The total data buffer size of a hairpin queue (logarithmic form), in bytes.
PMD will set the data buffer size to 2 ** <code class="docutils literal notranslate"><span class="pre">hp_buf_log_sz</span></code>, both for RX &amp; TX.
The capacity of the value is specified by the firmware and the initialization
will get a failure if it is out of scope.
The range of the value is from 11 to 19 right now, and the supported frame
size of a single packet for hairpin is from 512B to 128KB. It might change if
different firmware release is being used. By using a small value, it could
reduce memory consumption but not work with a large frame. If the value is
too large, the memory consumption will be high and some potential performance
degradation will be introduced.
By default, the PMD will set this value to 16, which means that 9KB jumbo
frames will be supported.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">reclaim_mem_mode</span></code> parameter [int]</p>
<p>Cache some resources in flow destroy will help flow recreation more efficient.
While some systems may require the all the resources can be reclaimed after
flow destroyed.
The parameter <code class="docutils literal notranslate"><span class="pre">reclaim_mem_mode</span></code> provides the option for user to configure
if the resource cache is needed or not.</p>
<p>There are three options to choose:</p>
<ul class="simple">
<li><p>0. It means the flow resources will be cached as usual. The resources will
be cached, helpful with flow insertion rate.</p></li>
<li><ol class="arabic simple">
<li><p>It will only enable the DPDK PMD level resources reclaim.</p></li>
</ol>
</li>
<li><p>2. Both DPDK PMD level and rdma-core low level will be configured as
reclaimed mode.</p></li>
</ul>
<p>By default, the PMD will set this value to 0.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">sys_mem_en</span></code> parameter [int]</p>
<p>A non-zero value enables the PMD memory management allocating memory
from system by default, without explicit rte memory flag.</p>
<p>By default, the PMD will set this value to 0.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">decap_en</span></code> parameter [int]</p>
<p>Some devices do not support FCS (frame checksum) scattering for
tunnel-decapsulated packets.
If set to 0, this option forces the FCS feature and rejects tunnel
decapsulation in the flow engine for such devices.</p>
<p>By default, the PMD will set this value to 1.</p>
</li>
</ul>
</div>
</div>
<div class="section" id="firmware-configuration">
<span id="mlx5-firmware-config"></span><h3><span class="section-number">34.5.4. </span>Firmware configuration</h3>
<p>Firmware features can be configured as key/value pairs.</p>
<p>The command to set a value is:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>mlxconfig -d &lt;device&gt; set &lt;key&gt;=&lt;value&gt;
</pre></div>
</div>
<p>The command to query a value is:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>mlxconfig -d &lt;device&gt; query | grep &lt;key&gt;
</pre></div>
</div>
<p>The device name for the command <code class="docutils literal notranslate"><span class="pre">mlxconfig</span></code> can be either the PCI address,
or the mst device name found with:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>mst status
</pre></div>
</div>
<p>Below are some firmware configurations listed.</p>
<ul>
<li><p>link type:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>LINK_TYPE_P1
LINK_TYPE_P2
value: 1=Infiniband 2=Ethernet 3=VPI(auto-sense)
</pre></div>
</div>
</li>
<li><p>enable SR-IOV:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>SRIOV_EN=1
</pre></div>
</div>
</li>
<li><p>maximum number of SR-IOV virtual functions:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>NUM_OF_VFS=&lt;max&gt;
</pre></div>
</div>
</li>
<li><p>enable DevX (required by Direct Rules and other features):</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>UCTX_EN=1
</pre></div>
</div>
</li>
<li><p>aggressive CQE zipping:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>CQE_COMPRESSION=1
</pre></div>
</div>
</li>
<li><p>L3 VXLAN and VXLAN-GPE destination UDP port:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>IP_OVER_VXLAN_EN=1
IP_OVER_VXLAN_PORT=&lt;udp dport&gt;
</pre></div>
</div>
</li>
<li><p>enable VXLAN-GPE tunnel flow matching:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>FLEX_PARSER_PROFILE_ENABLE=0
or
FLEX_PARSER_PROFILE_ENABLE=2
</pre></div>
</div>
</li>
<li><p>enable IP-in-IP tunnel flow matching:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>FLEX_PARSER_PROFILE_ENABLE=0
</pre></div>
</div>
</li>
<li><p>enable MPLS flow matching:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>FLEX_PARSER_PROFILE_ENABLE=1
</pre></div>
</div>
</li>
<li><p>enable ICMP(code/type/identifier/sequence number) / ICMP6(code/type) fields matching:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>FLEX_PARSER_PROFILE_ENABLE=2
</pre></div>
</div>
</li>
<li><p>enable Geneve flow matching:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>FLEX_PARSER_PROFILE_ENABLE=0
or
FLEX_PARSER_PROFILE_ENABLE=1
</pre></div>
</div>
</li>
<li><p>enable GTP flow matching:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>FLEX_PARSER_PROFILE_ENABLE=3
</pre></div>
</div>
</li>
<li><p>enable eCPRI flow matching:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>FLEX_PARSER_PROFILE_ENABLE=4
PROG_PARSE_GRAPH=1
</pre></div>
</div>
</li>
</ul>
</div>
</div>
<div class="section" id="prerequisites">
<h2><span class="section-number">34.6. </span>Prerequisites</h2>
<p>This driver relies on external libraries and kernel drivers for resources
allocations and initialization. The following dependencies are not part of
DPDK and must be installed separately:</p>
<ul>
<li><p><strong>libibverbs</strong></p>
<p>User space Verbs framework used by librte_net_mlx5. This library provides
a generic interface between the kernel and low-level user space drivers
such as libmlx5.</p>
<p>It allows slow and privileged operations (context initialization, hardware
resources allocations) to be managed by the kernel and fast operations to
never leave user space.</p>
</li>
<li><p><strong>libmlx5</strong></p>
<p>Low-level user space driver library for Mellanox
ConnectX-4/ConnectX-5/ConnectX-6/BlueField devices, it is automatically loaded
by libibverbs.</p>
<p>This library basically implements send/receive calls to the hardware
queues.</p>
</li>
<li><p><strong>Kernel modules</strong></p>
<p>They provide the kernel-side Verbs API and low level device drivers that
manage actual hardware initialization and resources sharing with user
space processes.</p>
<p>Unlike most other PMDs, these modules must remain loaded and bound to
their devices:</p>
<ul class="simple">
<li><p>mlx5_core: hardware driver managing Mellanox
ConnectX-4/ConnectX-5/ConnectX-6/BlueField devices and related Ethernet kernel
network devices.</p></li>
<li><p>mlx5_ib: InifiniBand device driver.</p></li>
<li><p>ib_uverbs: user space driver for Verbs (entry point for libibverbs).</p></li>
</ul>
</li>
<li><p><strong>Firmware update</strong></p>
<p>Mellanox OFED/EN releases include firmware updates for
ConnectX-4/ConnectX-5/ConnectX-6/BlueField adapters.</p>
<p>Because each release provides new features, these updates must be applied to
match the kernel modules and libraries they come with.</p>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Both libraries are BSD and GPL licensed. Linux kernel modules are GPL
licensed.</p>
</div>
<div class="section" id="installation">
<h3><span class="section-number">34.6.1. </span>Installation</h3>
<p>Either RDMA Core library with a recent enough Linux kernel release
(recommended) or Mellanox OFED/EN, which provides compatibility with older
releases.</p>
<div class="section" id="rdma-core-with-linux-kernel">
<h4><span class="section-number">34.6.1.1. </span>RDMA Core with Linux Kernel</h4>
<ul>
<li><p>Minimal kernel version : v4.14 or the most recent 4.14-rc (see <a class="reference external" href="https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git/plain/Documentation/admin-guide/README.rst">Linux installation documentation</a>)</p></li>
<li><p>Minimal rdma-core version: v15+ commit 0c5f5765213a (“Merge pull request #227 from yishaih/tm”)
(see <a class="reference external" href="https://raw.githubusercontent.com/linux-rdma/rdma-core/master/README.md">RDMA Core installation documentation</a>)</p></li>
<li><p>When building for i686 use:</p>
<ul class="simple">
<li><p>rdma-core version 18.0 or above built with 32bit support.</p></li>
<li><p>Kernel version 4.14.41 or above.</p></li>
</ul>
</li>
<li><p>Starting with rdma-core v21, static libraries can be built:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>cd build
CFLAGS=-fPIC cmake -DIN_PLACE=1 -DENABLE_STATIC=1 -GNinja ..
ninja
</pre></div>
</div>
</li>
</ul>
</div>
<div class="section" id="mellanox-ofed-en">
<h4><span class="section-number">34.6.1.2. </span>Mellanox OFED/EN</h4>
<ul class="simple">
<li><p>Mellanox OFED version: <strong>4.5</strong> and above /
Mellanox EN version: <strong>4.5</strong> and above</p></li>
<li><p>firmware version:</p>
<ul>
<li><p>ConnectX-4: <strong>12.21.1000</strong> and above.</p></li>
<li><p>ConnectX-4 Lx: <strong>14.21.1000</strong> and above.</p></li>
<li><p>ConnectX-5: <strong>16.21.1000</strong> and above.</p></li>
<li><p>ConnectX-5 Ex: <strong>16.21.1000</strong> and above.</p></li>
<li><p>ConnectX-6: <strong>20.27.0090</strong> and above.</p></li>
<li><p>ConnectX-6 Dx: <strong>22.27.0090</strong> and above.</p></li>
<li><p>BlueField: <strong>18.25.1010</strong> and above.</p></li>
</ul>
</li>
</ul>
<p>While these libraries and kernel modules are available on OpenFabrics
Alliance’s <a class="reference external" href="https://www.openfabrics.org/">website</a> and provided by package
managers on most distributions, this PMD requires Ethernet extensions that
may not be supported at the moment (this is a work in progress).</p>
<p><a class="reference external" href="http://www.mellanox.com/page/products_dyn?product_family=26&amp;mtag=linux">Mellanox OFED</a> and
<a class="reference external" href="http://www.mellanox.com/page/products_dyn?product_family=27&amp;mtag=linux">Mellanox EN</a>
include the necessary support and should be used in the meantime. For DPDK,
only libibverbs, libmlx5, mlnx-ofed-kernel packages and firmware updates are
required from that distribution.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Several versions of Mellanox OFED/EN are available. Installing the version
this DPDK release was developed and tested against is strongly
recommended. Please check the <a class="reference internal" href="#prerequisites">prerequisites</a>.</p>
</div>
</div>
</div>
</div>
<div class="section" id="supported-nics">
<h2><span class="section-number">34.7. </span>Supported NICs</h2>
<p>The following Mellanox device families are supported by the same mlx5 driver:</p>
<blockquote>
<div><ul class="simple">
<li><p>ConnectX-4</p></li>
<li><p>ConnectX-4 Lx</p></li>
<li><p>ConnectX-5</p></li>
<li><p>ConnectX-5 Ex</p></li>
<li><p>ConnectX-6</p></li>
<li><p>ConnectX-6 Dx</p></li>
<li><p>ConnectX-6 Lx</p></li>
<li><p>BlueField</p></li>
<li><p>BlueField-2</p></li>
</ul>
</div></blockquote>
<p>Below are detailed device names:</p>
<ul class="simple">
<li><p>Mellanox® ConnectX®-4 10G MCX4111A-XCAT (1x10G)</p></li>
<li><p>Mellanox® ConnectX®-4 10G MCX412A-XCAT (2x10G)</p></li>
<li><p>Mellanox® ConnectX®-4 25G MCX4111A-ACAT (1x25G)</p></li>
<li><p>Mellanox® ConnectX®-4 25G MCX412A-ACAT (2x25G)</p></li>
<li><p>Mellanox® ConnectX®-4 40G MCX413A-BCAT (1x40G)</p></li>
<li><p>Mellanox® ConnectX®-4 40G MCX4131A-BCAT (1x40G)</p></li>
<li><p>Mellanox® ConnectX®-4 40G MCX415A-BCAT (1x40G)</p></li>
<li><p>Mellanox® ConnectX®-4 50G MCX413A-GCAT (1x50G)</p></li>
<li><p>Mellanox® ConnectX®-4 50G MCX4131A-GCAT (1x50G)</p></li>
<li><p>Mellanox® ConnectX®-4 50G MCX414A-BCAT (2x50G)</p></li>
<li><p>Mellanox® ConnectX®-4 50G MCX415A-GCAT (1x50G)</p></li>
<li><p>Mellanox® ConnectX®-4 50G MCX416A-BCAT (2x50G)</p></li>
<li><p>Mellanox® ConnectX®-4 50G MCX416A-GCAT (2x50G)</p></li>
<li><p>Mellanox® ConnectX®-4 50G MCX415A-CCAT (1x100G)</p></li>
<li><p>Mellanox® ConnectX®-4 100G MCX416A-CCAT (2x100G)</p></li>
<li><p>Mellanox® ConnectX®-4 Lx 10G MCX4111A-XCAT (1x10G)</p></li>
<li><p>Mellanox® ConnectX®-4 Lx 10G MCX4121A-XCAT (2x10G)</p></li>
<li><p>Mellanox® ConnectX®-4 Lx 25G MCX4111A-ACAT (1x25G)</p></li>
<li><p>Mellanox® ConnectX®-4 Lx 25G MCX4121A-ACAT (2x25G)</p></li>
<li><p>Mellanox® ConnectX®-4 Lx 40G MCX4131A-BCAT (1x40G)</p></li>
<li><p>Mellanox® ConnectX®-5 100G MCX556A-ECAT (2x100G)</p></li>
<li><p>Mellanox® ConnectX®-5 Ex EN 100G MCX516A-CDAT (2x100G)</p></li>
<li><p>Mellanox® ConnectX®-6 200G MCX654106A-HCAT (2x200G)</p></li>
<li><p>Mellanox® ConnectX®-6 Dx EN 100G MCX623106AN-CDAT (2x100G)</p></li>
<li><p>Mellanox® ConnectX®-6 Dx EN 200G MCX623105AN-VDAT (1x200G)</p></li>
<li><p>Mellanox® ConnectX®-6 Lx EN 25G MCX631102AN-ADAT (2x25G)</p></li>
</ul>
</div>
<div class="section" id="quick-start-guide-on-ofed-en">
<h2><span class="section-number">34.8. </span>Quick Start Guide on OFED/EN</h2>
<ol class="arabic">
<li><p>Download latest Mellanox OFED/EN. For more info check the  <a class="reference internal" href="#prerequisites">prerequisites</a>.</p></li>
<li><p>Install the required libraries and kernel modules either by installing
only the required set, or by installing the entire Mellanox OFED/EN:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>./mlnxofedinstall --upstream-libs --dpdk
</pre></div>
</div>
</li>
<li><p>Verify the firmware is the correct one:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ibv_devinfo
</pre></div>
</div>
</li>
<li><p>Verify all ports links are set to Ethernet:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>mlxconfig -d &lt;mst device&gt; query | grep LINK_TYPE
LINK_TYPE_P1                        ETH(2)
LINK_TYPE_P2                        ETH(2)
</pre></div>
</div>
<p>Link types may have to be configured to Ethernet:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>mlxconfig -d &lt;mst device&gt; set LINK_TYPE_P1/2=1/2/3

* LINK_TYPE_P1=&lt;1|2|3&gt; , 1=Infiniband 2=Ethernet 3=VPI(auto-sense)
</pre></div>
</div>
<p>For hypervisors, verify SR-IOV is enabled on the NIC:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>mlxconfig -d &lt;mst device&gt; query | grep SRIOV_EN
SRIOV_EN                            True(1)
</pre></div>
</div>
<p>If needed, configure SR-IOV:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>mlxconfig -d &lt;mst device&gt; set SRIOV_EN=1 NUM_OF_VFS=16
mlxfwreset -d &lt;mst device&gt; reset
</pre></div>
</div>
</li>
<li><p>Restart the driver:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>/etc/init.d/openibd restart
</pre></div>
</div>
<p>or:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>service openibd restart
</pre></div>
</div>
<p>If link type was changed, firmware must be reset as well:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>mlxfwreset -d &lt;mst device&gt; reset
</pre></div>
</div>
<p>For hypervisors, after reset write the sysfs number of virtual functions
needed for the PF.</p>
<p>To dynamically instantiate a given number of virtual functions (VFs):</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>echo [num_vfs] &gt; /sys/class/infiniband/mlx5_0/device/sriov_numvfs
</pre></div>
</div>
</li>
<li><p>Install DPDK and you are ready to go.
See <a class="reference internal" href="../linux_gsg/build_dpdk.html"><span class="doc">compilation instructions</span></a>.</p></li>
</ol>
</div>
<div class="section" id="enable-switchdev-mode">
<h2><span class="section-number">34.9. </span>Enable switchdev mode</h2>
<p>Switchdev mode is a mode in E-Switch, that binds between representor and VF.
Representor is a port in DPDK that is connected to a VF in such a way
that assuming there are no offload flows, each packet that is sent from the VF
will be received by the corresponding representor. While each packet that is
sent to a representor will be received by the VF.
This is very useful in case of SRIOV mode, where the first packet that is sent
by the VF will be received by the DPDK application which will decide if this
flow should be offloaded to the E-Switch. After offloading the flow packet
that the VF that are matching the flow will not be received any more by
the DPDK application.</p>
<ol class="arabic">
<li><p>Enable SRIOV mode:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>mlxconfig -d &lt;mst device&gt; set SRIOV_EN=true
</pre></div>
</div>
</li>
<li><p>Configure the max number of VFs:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>mlxconfig -d &lt;mst device&gt; set NUM_OF_VFS=&lt;num of vfs&gt;
</pre></div>
</div>
</li>
<li><p>Reset the FW:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>mlxfwreset -d &lt;mst device&gt; reset
</pre></div>
</div>
</li>
</ol>
<ol class="arabic" start="3">
<li><p>Configure the actual number of VFs:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>echo &lt;num of vfs &gt; /sys/class/net/&lt;net device&gt;/device/sriov_numvfs
</pre></div>
</div>
</li>
<li><p>Unbind the device (can be rebind after the switchdev mode):</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>echo -n &quot;&lt;device pci address&quot; &gt; /sys/bus/pci/drivers/mlx5_core/unbind
</pre></div>
</div>
</li>
<li><p>Enbale switchdev mode:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>echo switchdev &gt; /sys/class/net/&lt;net device&gt;/compat/devlink/mode
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="performance-tuning">
<h2><span class="section-number">34.10. </span>Performance tuning</h2>
<ol class="arabic">
<li><p>Configure aggressive CQE Zipping for maximum performance:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>mlxconfig -d &lt;mst device&gt; s CQE_COMPRESSION=1
</pre></div>
</div>
</li>
</ol>
<blockquote>
<div><p>To set it back to the default CQE Zipping mode use:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>mlxconfig -d &lt;mst device&gt; s CQE_COMPRESSION=0
</pre></div>
</div>
</div></blockquote>
<ol class="arabic" start="2">
<li><p>In case of virtualization:</p>
<ul class="simple">
<li><p>Make sure that hypervisor kernel is 3.16 or newer.</p></li>
<li><p>Configure boot with <code class="docutils literal notranslate"><span class="pre">iommu=pt</span></code>.</p></li>
<li><p>Use 1G huge pages.</p></li>
<li><p>Make sure to allocate a VM on huge pages.</p></li>
<li><p>Make sure to set CPU pinning.</p></li>
</ul>
</li>
<li><p>Use the CPU near local NUMA node to which the PCIe adapter is connected,
for better performance. For VMs, verify that the right CPU
and NUMA node are pinned according to the above. Run:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>lstopo-no-graphics
</pre></div>
</div>
<p>to identify the NUMA node to which the PCIe adapter is connected.</p>
</li>
<li><p>If more than one adapter is used, and root complex capabilities allow
to put both adapters on the same NUMA node without PCI bandwidth degradation,
it is recommended to locate both adapters on the same NUMA node.
This in order to forward packets from one to the other without
NUMA performance penalty.</p></li>
<li><p>Disable pause frames:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ethtool -A &lt;netdev&gt; rx off tx off
</pre></div>
</div>
</li>
<li><p>Verify IO non-posted prefetch is disabled by default. This can be checked
via the BIOS configuration. Please contact you server provider for more
information about the settings.</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>On some machines, depends on the machine integrator, it is beneficial
to set the PCI max read request parameter to 1K. This can be
done in the following way:</p>
<p>To query the read request size use:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>setpci -s &lt;NIC PCI address&gt; 68.w
</pre></div>
</div>
<p>If the output is different than 3XXX, set it by:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>setpci -s &lt;NIC PCI address&gt; 68.w=3XXX
</pre></div>
</div>
<p>The XXX can be different on different systems. Make sure to configure
according to the setpci output.</p>
</div>
<ol class="arabic simple" start="7">
<li><p>To minimize overhead of searching Memory Regions:</p>
<ul class="simple">
<li><p>‘–socket-mem’ is recommended to pin memory by predictable amount.</p></li>
<li><p>Configure per-lcore cache when creating Mempools for packet buffer.</p></li>
<li><p>Refrain from dynamically allocating/freeing memory in run-time.</p></li>
</ul>
</li>
</ol>
</div>
<div class="section" id="rx-burst-functions">
<h2><span class="section-number">34.11. </span>Rx burst functions</h2>
<p>There are multiple Rx burst functions with different advantages and limitations.</p>
<table class="docutils align-default" id="id1">
<caption><span class="caption-number">Table 34.1 </span><span class="caption-text">Rx burst functions</span></caption>
<colgroup>
<col style="width: 23%" />
<col style="width: 29%" />
<col style="width: 11%" />
<col style="width: 21%" />
<col style="width: 7%" />
<col style="width: 9%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><div class="line-block">
<div class="line">Function Name</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">Enabler</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">Scatter</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">Error Recovery</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">CQE</div>
<div class="line">comp</div>
</div>
</th>
<th class="head"><div class="line-block">
<div class="line">Large</div>
<div class="line">MTU</div>
</div>
</th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>rx_burst</p></td>
<td><p>rx_vec_en=0</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p>rx_burst_vec</p></td>
<td><p>rx_vec_en=1 (default)</p></td>
<td><p>No</p></td>
<td><p>if CQE comp off</p></td>
<td><p>Yes</p></td>
<td><p>No</p></td>
</tr>
<tr class="row-even"><td><p>rx_burst_mprq</p></td>
<td><div class="line-block">
<div class="line">mprq_en=1</div>
<div class="line">RxQs &gt;= rxqs_min_mprq</div>
</div>
</td>
<td><p>No</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
</tr>
<tr class="row-odd"><td><p>rx_burst_mprq_vec</p></td>
<td><div class="line-block">
<div class="line">rx_vec_en=1 (default)</div>
<div class="line">mprq_en=1</div>
<div class="line">RxQs &gt;= rxqs_min_mprq</div>
</div>
</td>
<td><p>No</p></td>
<td><p>if CQE comp off</p></td>
<td><p>Yes</p></td>
<td><p>Yes</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="supported-hardware-offloads">
<span id="mlx5-offloads-support"></span><h2><span class="section-number">34.12. </span>Supported hardware offloads</h2>
<table class="docutils align-default" id="id2">
<caption><span class="caption-number">Table 34.2 </span><span class="caption-text">Minimal SW/HW versions for queue offloads</span></caption>
<colgroup>
<col style="width: 23%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 15%" />
<col style="width: 8%" />
<col style="width: 16%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Offload</p></th>
<th class="head"><p>DPDK</p></th>
<th class="head"><p>Linux</p></th>
<th class="head"><p>rdma-core</p></th>
<th class="head"><p>OFED</p></th>
<th class="head"><p>firmware</p></th>
<th class="head"><p>hardware</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>common base</p></td>
<td><p>17.11</p></td>
<td><p>4.14</p></td>
<td><p>16</p></td>
<td><p>4.2-1</p></td>
<td><p>12.21.1000</p></td>
<td><p>ConnectX-4</p></td>
</tr>
<tr class="row-odd"><td><p>checksums</p></td>
<td><p>17.11</p></td>
<td><p>4.14</p></td>
<td><p>16</p></td>
<td><p>4.2-1</p></td>
<td><p>12.21.1000</p></td>
<td><p>ConnectX-4</p></td>
</tr>
<tr class="row-even"><td><p>Rx timestamp</p></td>
<td><p>17.11</p></td>
<td><p>4.14</p></td>
<td><p>16</p></td>
<td><p>4.2-1</p></td>
<td><p>12.21.1000</p></td>
<td><p>ConnectX-4</p></td>
</tr>
<tr class="row-odd"><td><p>TSO</p></td>
<td><p>17.11</p></td>
<td><p>4.14</p></td>
<td><p>16</p></td>
<td><p>4.2-1</p></td>
<td><p>12.21.1000</p></td>
<td><p>ConnectX-4</p></td>
</tr>
<tr class="row-even"><td><p>LRO</p></td>
<td><p>19.08</p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
<td><p>4.6-4</p></td>
<td><p>16.25.6406</p></td>
<td><p>ConnectX-5</p></td>
</tr>
<tr class="row-odd"><td><p>Buffer Split</p></td>
<td><p>20.11</p></td>
<td><p>N/A</p></td>
<td><p>N/A</p></td>
<td><p>5.1-2</p></td>
<td><p>22.28.2006</p></td>
<td><p>ConnectX-6 Dx</p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default" id="id3">
<caption><span class="caption-number">Table 34.3 </span><span class="caption-text">Minimal SW/HW versions for rte_flow offloads</span></caption>
<colgroup>
<col style="width: 40%" />
<col style="width: 30%" />
<col style="width: 30%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Offload</p></th>
<th class="head"><p>with E-Switch</p></th>
<th class="head"><p>with NIC</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Count</p></td>
<td><div class="line-block">
<div class="line">DPDK 19.05</div>
<div class="line">OFED 4.6</div>
<div class="line">rdma-core 24</div>
<div class="line">ConnectX-5</div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 19.02</div>
<div class="line">OFED 4.6</div>
<div class="line">rdma-core 23</div>
<div class="line">ConnectX-5</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>Drop</p></td>
<td><div class="line-block">
<div class="line">DPDK 19.05</div>
<div class="line">OFED 4.6</div>
<div class="line">rdma-core 24</div>
<div class="line">ConnectX-5</div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 18.11</div>
<div class="line">OFED 4.5</div>
<div class="line">rdma-core 23</div>
<div class="line">ConnectX-4</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>Queue / RSS</p></td>
<td><div class="line-block">
<div class="line"><br /></div>
<div class="line-block">
<div class="line">N/A</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 18.11</div>
<div class="line">OFED 4.5</div>
<div class="line">rdma-core 23</div>
<div class="line">ConnectX-4</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>RSS shared action</p></td>
<td><div class="line-block">
<div class="line"><br /></div>
<div class="line-block">
<div class="line">N/A</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 20.11</div>
<div class="line">OFED 5.2</div>
<div class="line">rdma-core 33</div>
<div class="line">ConnectX-5</div>
</div>
</td>
</tr>
<tr class="row-even"><td><div class="line-block">
<div class="line">VLAN</div>
<div class="line">(of_pop_vlan /</div>
<div class="line">of_push_vlan /</div>
<div class="line">of_set_vlan_pcp /</div>
<div class="line">of_set_vlan_vid)</div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 19.11</div>
<div class="line">OFED 4.7-1</div>
<div class="line">ConnectX-5</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 19.11</div>
<div class="line">OFED 4.7-1</div>
<div class="line">ConnectX-5</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>Encapsulation
(VXLAN / NVGRE / RAW)</p></td>
<td><div class="line-block">
<div class="line">DPDK 19.05</div>
<div class="line">OFED 4.7-1</div>
<div class="line">rdma-core 24</div>
<div class="line">ConnectX-5</div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 19.02</div>
<div class="line">OFED 4.6</div>
<div class="line">rdma-core 23</div>
<div class="line">ConnectX-5</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>Encapsulation
GENEVE</p></td>
<td><div class="line-block">
<div class="line">DPDK 19.11</div>
<div class="line">OFED 4.7-3</div>
<div class="line">rdma-core 27</div>
<div class="line">ConnectX-5</div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 19.11</div>
<div class="line">OFED 4.7-3</div>
<div class="line">rdma-core 27</div>
<div class="line">ConnectX-5</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>Tunnel Offload</p></td>
<td><div class="line-block">
<div class="line">DPDK 20.11</div>
<div class="line">OFED 5.1-2</div>
<div class="line">rdma-core 32</div>
<div class="line">ConnectX-5</div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 20.11</div>
<div class="line">OFED 5.1-2</div>
<div class="line">N/A</div>
<div class="line">ConnectX-5</div>
</div>
</td>
</tr>
<tr class="row-even"><td><div class="line-block">
<div class="line">Header rewrite</div>
<div class="line">(set_ipv4_src /</div>
<div class="line">set_ipv4_dst /</div>
<div class="line">set_ipv6_src /</div>
<div class="line">set_ipv6_dst /</div>
<div class="line">set_tp_src /</div>
<div class="line">set_tp_dst /</div>
<div class="line">dec_ttl /</div>
<div class="line">set_ttl /</div>
<div class="line">set_mac_src /</div>
<div class="line">set_mac_dst)</div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 19.05</div>
<div class="line">OFED 4.7-1</div>
<div class="line">rdma-core 24</div>
<div class="line">ConnectX-5</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 19.02</div>
<div class="line">OFED 4.7-1</div>
<div class="line">rdma-core 24</div>
<div class="line">ConnectX-5</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
</tr>
<tr class="row-odd"><td><div class="line-block">
<div class="line">Header rewrite</div>
<div class="line">(set_dscp)</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 20.02</div>
<div class="line">OFED 5.0</div>
<div class="line">rdma-core 24</div>
<div class="line">ConnectX-5</div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 20.02</div>
<div class="line">OFED 5.0</div>
<div class="line">rdma-core 24</div>
<div class="line">ConnectX-5</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>Jump</p></td>
<td><div class="line-block">
<div class="line">DPDK 19.05</div>
<div class="line">OFED 4.7-1</div>
<div class="line">rdma-core 24</div>
<div class="line">ConnectX-5</div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 19.02</div>
<div class="line">OFED 4.7-1</div>
<div class="line">N/A</div>
<div class="line">ConnectX-5</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>Mark / Flag</p></td>
<td><div class="line-block">
<div class="line">DPDK 19.05</div>
<div class="line">OFED 4.6</div>
<div class="line">rdma-core 24</div>
<div class="line">ConnectX-5</div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 18.11</div>
<div class="line">OFED 4.5</div>
<div class="line">rdma-core 23</div>
<div class="line">ConnectX-4</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>Meta data</p></td>
<td><div class="line-block">
<div class="line">DPDK 19.11</div>
<div class="line">OFED 4.7-3</div>
<div class="line">rdma-core 26</div>
<div class="line">ConnectX-5</div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 19.11</div>
<div class="line">OFED 4.7-3</div>
<div class="line">rdma-core 26</div>
<div class="line">ConnectX-5</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>Port ID</p></td>
<td><div class="line-block">
<div class="line">DPDK 19.05</div>
<div class="line">OFED 4.7-1</div>
<div class="line">rdma-core 24</div>
<div class="line">ConnectX-5</div>
</div>
</td>
<td><div class="line-block">
<div class="line">N/A</div>
<div class="line">N/A</div>
<div class="line">N/A</div>
<div class="line">N/A</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>Hairpin</p></td>
<td><div class="line-block">
<div class="line"><br /></div>
<div class="line-block">
<div class="line">N/A</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 19.11</div>
<div class="line">OFED 4.7-3</div>
<div class="line">rdma-core 26</div>
<div class="line">ConnectX-5</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>2-port Hairpin</p></td>
<td><div class="line-block">
<div class="line"><br /></div>
<div class="line-block">
<div class="line">N/A</div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 20.11</div>
<div class="line">OFED 5.1-2</div>
<div class="line">N/A</div>
<div class="line">ConnectX-5</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>Metering</p></td>
<td><div class="line-block">
<div class="line">DPDK 19.11</div>
<div class="line">OFED 4.7-3</div>
<div class="line">rdma-core 26</div>
<div class="line">ConnectX-5</div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 19.11</div>
<div class="line">OFED 4.7-3</div>
<div class="line">rdma-core 26</div>
<div class="line">ConnectX-5</div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>Sampling</p></td>
<td><div class="line-block">
<div class="line">DPDK 20.11</div>
<div class="line">OFED 5.1-2</div>
<div class="line">rdma-core 32</div>
<div class="line">ConnectX-5</div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 20.11</div>
<div class="line">OFED 5.1-2</div>
<div class="line">N/A</div>
<div class="line">ConnectX-5</div>
</div>
</td>
</tr>
<tr class="row-even"><td><p>Age shared action</p></td>
<td><div class="line-block">
<div class="line">DPDK 20.11</div>
<div class="line">OFED 5.2</div>
<div class="line">rdma-core 32</div>
<div class="line">ConnectX-6 Dx</div>
</div>
</td>
<td><div class="line-block">
<div class="line">DPDK 20.11</div>
<div class="line">OFED 5.2</div>
<div class="line">rdma-core 32</div>
<div class="line">ConnectX-6 Dx</div>
</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="notes-for-metadata">
<h2><span class="section-number">34.13. </span>Notes for metadata</h2>
<p>MARK and META items are interrelated with datapath - they might move from/to
the applications in mbuf fields. Hence, zero value for these items has the
special meaning - it means “no metadata are provided”, not zero values are
treated by applications and PMD as valid ones.</p>
<p>Moreover in the flow engine domain the value zero is acceptable to match and
set, and we should allow to specify zero values as rte_flow parameters for the
META and MARK items and actions. In the same time zero mask has no meaning and
should be rejected on validation stage.</p>
</div>
<div class="section" id="notes-for-rte-flow">
<h2><span class="section-number">34.14. </span>Notes for rte_flow</h2>
<p>Flows are not cached in the driver.
When stopping a device port, all the flows created on this port from the
application will be flushed automatically in the background.
After stopping the device port, all flows on this port become invalid and
not represented in the system.
All references to these flows held by the application should be discarded
directly but neither destroyed nor flushed.</p>
<p>The application should re-create the flows as required after the port restart.</p>
</div>
<div class="section" id="notes-for-testpmd">
<h2><span class="section-number">34.15. </span>Notes for testpmd</h2>
<p>Compared to librte_net_mlx4 that implements a single RSS configuration per
port, librte_net_mlx5 supports per-protocol RSS configuration.</p>
<p>Since <code class="docutils literal notranslate"><span class="pre">testpmd</span></code> defaults to IP RSS mode and there is currently no
command-line parameter to enable additional protocols (UDP and TCP as well
as IP), the following commands must be entered from its CLI to get the same
behavior as librte_net_mlx4:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&gt; port stop all
&gt; port config all rss all
&gt; port start all
</pre></div>
</div>
</div>
<div class="section" id="usage-example">
<h2><span class="section-number">34.16. </span>Usage example</h2>
<p>This section demonstrates how to launch <strong>testpmd</strong> with Mellanox
ConnectX-4/ConnectX-5/ConnectX-6/BlueField devices managed by librte_net_mlx5.</p>
<ol class="arabic">
<li><p>Load the kernel modules:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>modprobe -a ib_uverbs mlx5_core mlx5_ib
</pre></div>
</div>
<p>Alternatively if MLNX_OFED/MLNX_EN is fully installed, the following script
can be run:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>/etc/init.d/openibd restart
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>User space I/O kernel modules (uio and igb_uio) are not used and do
not have to be loaded.</p>
</div>
</li>
<li><p>Make sure Ethernet interfaces are in working order and linked to kernel
verbs. Related sysfs entries should be present:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>ls -d /sys/class/net/*/device/infiniband_verbs/uverbs* | cut -d / -f 5
</pre></div>
</div>
<p>Example output:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>eth30
eth31
eth32
eth33
</pre></div>
</div>
</li>
<li><p>Optionally, retrieve their PCI bus addresses for to be used with the allow list:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>{
    for intf in eth2 eth3 eth4 eth5;
    do
        (cd &quot;/sys/class/net/${intf}/device/&quot; &amp;&amp; pwd -P);
    done;
} |
sed -n &#39;s,.*/\(.*\),-a \1,p&#39;
</pre></div>
</div>
<p>Example output:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-a 0000:05:00.1
-a 0000:06:00.0
-a 0000:06:00.1
-a 0000:05:00.0
</pre></div>
</div>
</li>
<li><p>Request huge pages:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>echo 1024 &gt; /sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages/nr_hugepages
</pre></div>
</div>
</li>
<li><p>Start testpmd with basic parameters:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>testpmd -l 8-15 -n 4 -a 05:00.0 -a 05:00.1 -a 06:00.0 -a 06:00.1 -- --rxq=2 --txq=2 -i
</pre></div>
</div>
<p>Example output:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>[...]
EAL: PCI device 0000:05:00.0 on NUMA socket 0
EAL:   probe driver: 15b3:1013 librte_net_mlx5
PMD: librte_net_mlx5: PCI information matches, using device &quot;mlx5_0&quot; (VF: false)
PMD: librte_net_mlx5: 1 port(s) detected
PMD: librte_net_mlx5: port 1 MAC address is e4:1d:2d:e7:0c:fe
EAL: PCI device 0000:05:00.1 on NUMA socket 0
EAL:   probe driver: 15b3:1013 librte_net_mlx5
PMD: librte_net_mlx5: PCI information matches, using device &quot;mlx5_1&quot; (VF: false)
PMD: librte_net_mlx5: 1 port(s) detected
PMD: librte_net_mlx5: port 1 MAC address is e4:1d:2d:e7:0c:ff
EAL: PCI device 0000:06:00.0 on NUMA socket 0
EAL:   probe driver: 15b3:1013 librte_net_mlx5
PMD: librte_net_mlx5: PCI information matches, using device &quot;mlx5_2&quot; (VF: false)
PMD: librte_net_mlx5: 1 port(s) detected
PMD: librte_net_mlx5: port 1 MAC address is e4:1d:2d:e7:0c:fa
EAL: PCI device 0000:06:00.1 on NUMA socket 0
EAL:   probe driver: 15b3:1013 librte_net_mlx5
PMD: librte_net_mlx5: PCI information matches, using device &quot;mlx5_3&quot; (VF: false)
PMD: librte_net_mlx5: 1 port(s) detected
PMD: librte_net_mlx5: port 1 MAC address is e4:1d:2d:e7:0c:fb
Interactive-mode selected
Configuring Port 0 (socket 0)
PMD: librte_net_mlx5: 0x8cba80: TX queues number update: 0 -&gt; 2
PMD: librte_net_mlx5: 0x8cba80: RX queues number update: 0 -&gt; 2
Port 0: E4:1D:2D:E7:0C:FE
Configuring Port 1 (socket 0)
PMD: librte_net_mlx5: 0x8ccac8: TX queues number update: 0 -&gt; 2
PMD: librte_net_mlx5: 0x8ccac8: RX queues number update: 0 -&gt; 2
Port 1: E4:1D:2D:E7:0C:FF
Configuring Port 2 (socket 0)
PMD: librte_net_mlx5: 0x8cdb10: TX queues number update: 0 -&gt; 2
PMD: librte_net_mlx5: 0x8cdb10: RX queues number update: 0 -&gt; 2
Port 2: E4:1D:2D:E7:0C:FA
Configuring Port 3 (socket 0)
PMD: librte_net_mlx5: 0x8ceb58: TX queues number update: 0 -&gt; 2
PMD: librte_net_mlx5: 0x8ceb58: RX queues number update: 0 -&gt; 2
Port 3: E4:1D:2D:E7:0C:FB
Checking link statuses...
Port 0 Link Up - speed 40000 Mbps - full-duplex
Port 1 Link Up - speed 40000 Mbps - full-duplex
Port 2 Link Up - speed 10000 Mbps - full-duplex
Port 3 Link Up - speed 10000 Mbps - full-duplex
Done
testpmd&gt;
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="how-to-dump-flows">
<h2><span class="section-number">34.17. </span>How to dump flows</h2>
<p>This section demonstrates how to dump flows. Currently, it’s possible to dump
all flows with assistance of external tools.</p>
<ol class="arabic">
<li><p>2 ways to get flow raw file:</p>
<ul class="simple">
<li><p>Using testpmd CLI:</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">testpmd&gt; flow dump &lt;port&gt; &lt;output_file&gt;</span>
</pre></div>
</div>
<ul class="simple">
<li><p>call rte_flow_dev_dump api:</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">rte_flow_dev_dump(port, file, NULL);</span>
</pre></div>
</div>
</li>
<li><p>Dump human-readable flows from raw file:</p>
<p>Get flow parsing tool from: <a class="reference external" href="https://github.com/Mellanox/mlx_steering_dump">https://github.com/Mellanox/mlx_steering_dump</a></p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">mlx_steering_dump.py -f &lt;output_file&gt;</span>
</pre></div>
</div>
</li>
</ol>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="mvneta.html" class="btn btn-neutral float-right" title="35. MVNETA Poll Mode Driver" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="mlx4.html" class="btn btn-neutral float-left" title="33. MLX4 poll mode driver library" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>